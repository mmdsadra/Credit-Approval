{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fddc66",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47d4c75",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "input_limit = 100\n",
    "missing_data = '?'\n",
    "have_header = False\n",
    "character_missing_data = \"missing\"  # For now I have used most frequent character for missing values\n",
    "result_column = 1\n",
    "epoches = 10000\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a307417",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_col(df, arg, limit):\n",
    "    return df[arg][:limit].to_numpy()\n",
    "\n",
    "def init():\n",
    "    try:\n",
    "        if (have_header):\n",
    "            df = pd.read_csv(\"crx.xls\")\n",
    "        else:\n",
    "            df = pd.read_csv(\"crx.xls\", header = None)\n",
    "    except Exception as e:\n",
    "        print(\"file not found\\n\")\n",
    "        print(e+\"\\n\")\n",
    "    return df\n",
    "\n",
    "def get_features(df, n, limit):\n",
    "    datas = []\n",
    "    datas = df.iloc[:limit, :n]\n",
    "    return np.array(datas)\n",
    "\n",
    "def get_labels(df, n,limit):\n",
    "    datas = []\n",
    "    for i in range(result_column):\n",
    "        datas.append(get_col(df, n-i, limit))\n",
    "    return np.array(datas)\n",
    "\n",
    "def solve_missing_data(features):\n",
    "    n = features.shape[1]\n",
    "    for i in range(n):\n",
    "        zero_count = (features[:,i] == missing_data).sum()\n",
    "        if (zero_count > 0):\n",
    "            index_list = np.where((features[:,i] == missing_data))[0]\n",
    "            # TODO: I should change 0 index, It might be zero itself\n",
    "            if (isinstance(features[0, i], (int, float))):\n",
    "                avg = np.mean(features[:, i])\n",
    "                for j in index_list:\n",
    "                    features[j, i] = avg\n",
    "            else:\n",
    "                values, counts = np.unique(features[:, i], return_counts=True)\n",
    "                most_frequent = values[np.argmax(counts)]\n",
    "                for j in index_list:\n",
    "                    features[j, i] = most_frequent   \n",
    "    return features \n",
    "\n",
    "def features_convert_to_number(features):\n",
    "    m, n = features.shape\n",
    "    for i in range (n):\n",
    "        data = features[:, i]\n",
    "        if (isinstance(data[0], (int, float))):\n",
    "            continue\n",
    "        unique_data = np.unique(data)\n",
    "        len_unique_data = len(unique_data)\n",
    "        if (len_unique_data == 2):\n",
    "            for j in range (m):\n",
    "                if (data[j] == unique_data[0]):\n",
    "                    data[j] = 0\n",
    "                else:\n",
    "                    data[j] = 1\n",
    "        elif (len_unique_data > 2):\n",
    "            num_arr = np.arange(1, len_unique_data+1, dtype=float)\n",
    "            min = np.min(num_arr)\n",
    "            max = np.max(num_arr)\n",
    "            distance = max - min\n",
    "            for j in range(len_unique_data):\n",
    "                num_arr[j] -= min\n",
    "                num_arr[j] /= distance\n",
    "            for j in range (m):\n",
    "                idx = np.where(unique_data == data[j])[0][0]\n",
    "                data[j] = num_arr[idx]\n",
    "\n",
    "        features[:, i] = data\n",
    "    features = features.astype(float)\n",
    "    return features\n",
    "\n",
    "def labels_convert_to_number(lables):\n",
    "    n = lables.shape[1]\n",
    "    for i in range (n):\n",
    "        if (lables[0][i] == '+'):\n",
    "            lables[0][i] = 1\n",
    "        else:\n",
    "            lables[0][i] = 0\n",
    "    lables = lables.astype(float).flatten()\n",
    "    return lables\n",
    "\n",
    "def init_weights_bias(ntehta):\n",
    "    weights = np.zeros(ntehta)\n",
    "    bias = 0\n",
    "    return weights, bias\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def logreg_compute_gradiant(features, lables, thetas, bias):\n",
    "    m, n = features.shape\n",
    "    z = np.dot(features, thetas) + bias \n",
    "    predictions = sigmoid(z)\n",
    "    dw = (1/m) * np.dot(features.T, (predictions - lables))\n",
    "    db = (1/m) * np.sum(predictions - lables)\n",
    "    thetas = thetas - learning_rate * dw\n",
    "    bias = bias - learning_rate * db\n",
    "    return thetas, bias\n",
    "\n",
    "def logreg_compute_cost(features, lables, thetas, bias):\n",
    "    m = len(lables)\n",
    "    z = np.dot(features, thetas) + bias\n",
    "    prediction = sigmoid(z)\n",
    "    epsilon = 1e-15\n",
    "    prediction = np.clip(prediction, epsilon, 1 - epsilon)\n",
    "    cost = -np.mean(lables * np.log(prediction) + (1-lables) * np.log(1-prediction))\n",
    "    return cost\n",
    "\n",
    "def logistic_regression(features, lables, nrows, thetas, bias):\n",
    "    ncols = len(features)\n",
    "    cost_history = []\n",
    "    for epoch in range (epoches):\n",
    "        thetas, bias = logreg_compute_gradiant(features, lables, thetas, bias)\n",
    "        cost = logreg_compute_cost(features, lables, thetas, bias)\n",
    "        cost_history.append(cost)\n",
    "    return thetas, bias, cost_history\n",
    "        \n",
    "def get_test_inputs(df, n, limit):\n",
    "    datas = []\n",
    "    datas = df.iloc[limit:, :n]\n",
    "    datas = np.array(datas)\n",
    "    return datas\n",
    "\n",
    "def get_test_results(df, n, limit):\n",
    "    datas = []\n",
    "    datas = df.iloc[limit:, n]\n",
    "    datas = np.array(datas)\n",
    "    return datas\n",
    "\n",
    "def tresults_convert_to_number(test_results):\n",
    "    n = len(test_results)\n",
    "    for j in range (n):\n",
    "        if (test_results[j] == '+'):\n",
    "            test_results[j] = 1\n",
    "        else:\n",
    "            test_results[j] = 0\n",
    "    test_results = np.array(test_results)\n",
    "    return test_results\n",
    "\n",
    "def predict(x, y, thetas, bias):\n",
    "    n, m = x.shape\n",
    "    ylen = len(y)\n",
    "    z = np.dot(x, thetas) + bias\n",
    "    predictions = sigmoid(z)\n",
    "    plen = len(predictions)\n",
    "    for i in range(plen):\n",
    "        if (predictions[i] >= 0.5):\n",
    "            predictions[i] = 1\n",
    "        else:\n",
    "            predictions[i] = 0\n",
    "    success = 0\n",
    "    for i in range (plen):\n",
    "        if (predictions[i] == y[i]):\n",
    "            success += 1\n",
    "    return (success / ylen)\n",
    "\n",
    "def main():\n",
    "    df = init()\n",
    "    ninput_data = df.shape[0] - input_limit\n",
    "    if (ninput_data < 0):\n",
    "        ninput_data = df.shape[0]\n",
    "        ninput_test = 0\n",
    "    else:\n",
    "        ninput_test = input_limit\n",
    "    nfeaurescols = df.shape[1] - result_column\n",
    "    features = get_features(df, nfeaurescols, ninput_data)\n",
    "    labels = get_labels(df, df.shape[1]-1, ninput_data)\n",
    "    features = solve_missing_data(features)\n",
    "    features = features_convert_to_number(features)\n",
    "    labels = labels_convert_to_number(labels)\n",
    "    theta_arr, bias = init_weights_bias(nfeaurescols)\n",
    "    theta_arr, bias, cost_history = logistic_regression(features, labels, ninput_data, theta_arr, bias)\n",
    "    if (ninput_test):\n",
    "        test_inputs = get_test_inputs(df, nfeaurescols, ninput_data)\n",
    "        test_results = get_test_results(df, nfeaurescols, ninput_data)\n",
    "        test_results = tresults_convert_to_number(test_results)\n",
    "        test_inputs = solve_missing_data(test_inputs)\n",
    "        test_inputs = features_convert_to_number(test_inputs)\n",
    "        sucess_percent = predict(test_inputs, test_results, theta_arr, bias)\n",
    "        print(sucess_percent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c15993",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
